/**
 * Adaptive Audio Engine v7.3.2
 * Integrates with Adaptive Mobile Audio System for optimal performance
 * 
 * Features:\n * - Device-aware configuration\n * - Automatic quality adjustment\n * - Performance monitoring\n * - Graceful degradation\n * - Memory management\n * - 64kbps MP3 prioritization\n */\n\nimport { AdaptiveMobileAudioSystem, AdaptiveAudioConfig, PerformanceMetrics } from './AdaptiveMobileAudioSystem';\nimport { AdaptiveSampleLoader } from './AdaptiveSampleLoader';\n\nexport interface TrackPattern {\n  id: string;\n  name: string;\n  steps: boolean[];\n  volume: number;\n  selectedSampleId: string;\n  muted: boolean;\n  groove?: GrooveDot[];\n}\n\nexport interface GrooveDot {\n  stepIndex: number;\n  offsetPercent: number;\n  offsetMs: number;\n}\n\nexport interface AudioPerformanceStats {\n  cpuUsage: number;\n  memoryUsage: number;\n  audioLatency: number;\n  droppedFrames: number;\n  currentPolyphony: number;\n  cacheHitRate: number;\n}\n\nexport class AdaptiveAudioEngine {\n  private audioContext: AudioContext;\n  private config: AdaptiveAudioConfig;\n  private sampleLoader: AdaptiveSampleLoader;\n  private tracks: Map<string, TrackPattern> = new Map();\n  private activeSources: Map<string, AudioBufferSourceNode[]> = new Map();\n  \n  // Playback state\n  private isPlaying: boolean = false;\n  private currentStep: number = 0;\n  private bpm: number = 100;\n  private nextStepTime: number = 0;\n  private schedulerInterval: number | null = null;\n  \n  // Performance monitoring\n  private performanceMonitor: PerformanceMonitor;\n  private qualityAdjustmentThreshold = 3; // Adjust after 3 performance issues\n  private performanceIssueCount = 0;\n  \n  // Adaptive configuration\n  private currentPolyphony = 0;\n  private maxPolyphony: number;\n  private memoryPressureLevel: 'low' | 'medium' | 'high' = 'low';\n  \n  constructor() {\n    this.performanceMonitor = new PerformanceMonitor();\n    console.log('üöÄ Initializing Adaptive Audio Engine v7.3.2...');\n  }\n  \n  /**\n   * Initialize the adaptive audio engine\n   */\n  async initialize(): Promise<void> {\n    try {\n      // Initialize adaptive system\n      this.config = await AdaptiveMobileAudioSystem.initialize();\n      \n      // Create optimized audio context\n      this.audioContext = await AdaptiveMobileAudioSystem.createOptimizedAudioContext();\n      \n      // Initialize sample loader\n      this.sampleLoader = new AdaptiveSampleLoader(this.audioContext, this.config);\n      \n      // Set adaptive parameters\n      this.maxPolyphony = this.config.maxPolyphony;\n      \n      // Start performance monitoring\n      if (this.config.adaptivePerformance) {\n        this.performanceMonitor.start((stats) => this.handlePerformanceUpdate(stats));\n      }\n      \n      console.log('‚úÖ Adaptive Audio Engine initialized successfully');\n      this.logEngineStatus();\n      \n      // Listen for config changes\n      window.addEventListener('audioConfigChanged', (event: any) => {\n        this.handleConfigChange(event.detail.config, event.detail.reason);\n      });\n      \n    } catch (error) {\n      console.error('‚ùå Failed to initialize Adaptive Audio Engine:', error);\n      throw error;\n    }\n  }\n  \n  /**\n   * Initialize tracks with pattern data\n   */\n  initializeTracks(tracks: TrackPattern[]): void {\n    console.log(`üéõÔ∏è Initializing ${tracks.length} tracks in adaptive audio engine`);\n    \n    this.tracks.clear();\n    tracks.forEach(track => {\n      this.tracks.set(track.id, {\n        ...track,\n        steps: [...track.steps]\n      });\n    });\n    \n    // Start adaptive preloading based on device capabilities\n    this.startAdaptivePreloading();\n    \n    console.log(`‚úÖ Adaptive audio engine initialized with tracks: ${Array.from(this.tracks.keys()).join(', ')}`);\n  }\n  \n  /**\n   * Start adaptive preloading based on device configuration\n   */\n  private async startAdaptivePreloading(): Promise<void> {\n    if (this.config.preloadStrategy === 'minimal') {\n      console.log('üì± Minimal preloading - only loading on-demand');\n      return;\n    }\n    \n    const sampleIds = Array.from(this.tracks.values())\n      .map(track => track.selectedSampleId)\n      .filter(id => id);\n    \n    console.log(`üîÑ Starting adaptive preloading for ${sampleIds.length} samples`);\n    \n    try {\n      await this.sampleLoader.preloadSamples(sampleIds, 'high');\n      console.log('‚úÖ Adaptive preloading completed');\n    } catch (error) {\n      console.warn('‚ö†Ô∏è Adaptive preloading failed:', error);\n    }\n  }\n  \n  /**\n   * Register sample path for adaptive loading\n   */\n  registerSamplePath(sampleId: string, samplePath: string): void {\n    // This is handled by the AdaptiveSampleLoader\n    console.log(`üìù Sample path registered: ${sampleId} -> ${samplePath.split('/').pop()}`);\n  }\n  \n  /**\n   * Load sample with adaptive strategy\n   */\n  async loadSample(sampleId: string): Promise<AudioBuffer | null> {\n    try {\n      return await this.sampleLoader.loadSample(sampleId);\n    } catch (error) {\n      console.error(`‚ùå Failed to load sample ${sampleId}:`, error);\n      return null;\n    }\n  }\n  \n  /**\n   * Play sample with adaptive polyphony management\n   */\n  playSample(sampleId: string, volume: number = 1.0, time?: number, trackId?: string): void {\n    const buffer = this.sampleLoader.getCachedSample(sampleId);\n    \n    if (!buffer) {\n      console.warn(`‚ö†Ô∏è Sample not cached for immediate playback: ${sampleId}`);\n      // Try to load and play asynchronously\n      this.loadAndPlaySample(sampleId, volume, time, trackId);\n      return;\n    }\n    \n    const playTime = time || this.audioContext.currentTime;\n    \n    // Adaptive polyphony management\n    if (this.currentPolyphony >= this.maxPolyphony) {\n      this.stopOldestSource(trackId);\n    }\n    \n    // Create and configure audio nodes\n    const source = this.audioContext.createBufferSource();\n    const gainNode = this.audioContext.createGain();\n    \n    source.buffer = buffer;\n    source.connect(gainNode);\n    gainNode.connect(this.audioContext.destination);\n    \n    // Apply dynamic range compression on mobile devices\n    if (this.config.deviceTier.includes('mobile')) {\n      gainNode.gain.setValueAtTime(volume * 0.8, playTime); // Slight volume reduction\n    } else {\n      gainNode.gain.setValueAtTime(volume, playTime);\n    }\n    \n    // Track active sources for polyphony management\n    if (trackId) {\n      if (!this.activeSources.has(trackId)) {\n        this.activeSources.set(trackId, []);\n      }\n      const sources = this.activeSources.get(trackId)!;\n      sources.push(source);\n      \n      source.onended = () => {\n        const idx = sources.indexOf(source);\n        if (idx > -1) {\n          sources.splice(idx, 1);\n          this.currentPolyphony = Math.max(0, this.currentPolyphony - 1);\n        }\n      };\n    }\n    \n    // Start playback\n    source.start(playTime);\n    this.currentPolyphony++;\n    \n    // Performance monitoring\n    this.performanceMonitor.recordSamplePlayback(sampleId, this.currentPolyphony);\n  }\n  \n  /**\n   * Load and play sample asynchronously\n   */\n  private async loadAndPlaySample(sampleId: string, volume: number, time?: number, trackId?: string): Promise<void> {\n    try {\n      const buffer = await this.sampleLoader.loadSample(sampleId);\n      if (buffer) {\n        // Check if we should still play (timing might have passed)\n        const currentTime = this.audioContext.currentTime;\n        const targetTime = time || currentTime;\n        \n        if (targetTime > currentTime - 0.1) { // Within 100ms tolerance\n          this.playSample(sampleId, volume, Math.max(targetTime, currentTime + 0.01), trackId);\n        }\n      }\n    } catch (error) {\n      console.error(`‚ùå Failed to load and play sample ${sampleId}:`, error);\n    }\n  }\n  \n  /**\n   * Play track sample with adaptive loading\n   */\n  async playTrackSample(trackId: string, volume: number = 1.0, time?: number): Promise<void> {\n    const track = this.tracks.get(trackId);\n    if (!track) {\n      console.error(`‚ùå Track not found: ${trackId}`);\n      return;\n    }\n    \n    const selectedSampleId = track.selectedSampleId;\n    if (!selectedSampleId) {\n      console.warn(`‚ö†Ô∏è No sample selected for track: ${trackId}`);\n      return;\n    }\n    \n    // Check if sample is cached for immediate playback\n    if (this.sampleLoader.isCached(selectedSampleId)) {\n      this.playSample(selectedSampleId, volume, time, trackId);\n    } else {\n      // Load and play asynchronously\n      console.log(`üîÑ Loading sample on-demand: ${selectedSampleId}`);\n      await this.loadAndPlaySample(selectedSampleId, volume, time, trackId);\n    }\n  }\n  \n  /**\n   * Handle performance updates\n   */\n  private handlePerformanceUpdate(stats: AudioPerformanceStats): void {\n    // Update memory pressure level\n    if (stats.memoryUsage > 0.85) {\n      this.memoryPressureLevel = 'high';\n    } else if (stats.memoryUsage > 0.7) {\n      this.memoryPressureLevel = 'medium';\n    } else {\n      this.memoryPressureLevel = 'low';\n    }\n    \n    // Check for performance issues\n    const hasPerformanceIssues = \n      stats.cpuUsage > 80 || \n      stats.memoryUsage > 0.9 || \n      stats.droppedFrames > 2 ||\n      stats.audioLatency > 100;\n    \n    if (hasPerformanceIssues) {\n      this.performanceIssueCount++;\n      console.warn(`‚ö†Ô∏è Performance issue detected (${this.performanceIssueCount}/${this.qualityAdjustmentThreshold}):`, {\n        CPU: `${stats.cpuUsage.toFixed(1)}%`,\n        Memory: `${(stats.memoryUsage * 100).toFixed(1)}%`,\n        Latency: `${stats.audioLatency.toFixed(1)}ms`,\n        DroppedFrames: stats.droppedFrames\n      });\n      \n      if (this.performanceIssueCount >= this.qualityAdjustmentThreshold) {\n        this.triggerQualityDegradation('Performance issues detected');\n      }\n    } else {\n      // Reset counter on good performance\n      this.performanceIssueCount = Math.max(0, this.performanceIssueCount - 1);\n    }\n  }\n  \n  /**\n   * Trigger quality degradation\n   */\n  private async triggerQualityDegradation(reason: string): Promise<void> {\n    console.log(`üîß Triggering adaptive quality degradation: ${reason}`);\n    \n    try {\n      const monitorResult = await AdaptiveMobileAudioSystem.monitorPerformance();\n      \n      if (monitorResult.shouldDegrade && monitorResult.newConfig) {\n        await this.applyNewConfiguration(monitorResult.newConfig, reason);\n        this.performanceIssueCount = 0; // Reset counter after adjustment\n      }\n    } catch (error) {\n      console.error('‚ùå Failed to apply quality degradation:', error);\n    }\n  }\n  \n  /**\n   * Apply new configuration\n   */\n  private async applyNewConfiguration(newConfig: AdaptiveAudioConfig, reason: string): Promise<void> {\n    console.log(`üîÑ Applying new adaptive configuration: ${newConfig.deviceTier}`);\n    \n    const oldConfig = this.config;\n    this.config = newConfig;\n    this.maxPolyphony = newConfig.maxPolyphony;\n    \n    // Update sample loader strategy\n    this.sampleLoader = new AdaptiveSampleLoader(this.audioContext, newConfig);\n    \n    // Clear some cache if memory pressure is high\n    if (this.memoryPressureLevel === 'high') {\n      this.sampleLoader.clearCache();\n      console.log('üóëÔ∏è Cleared sample cache due to memory pressure');\n    }\n    \n    // Reduce current polyphony if needed\n    if (this.currentPolyphony > this.maxPolyphony) {\n      this.reducePolyphony(this.maxPolyphony);\n    }\n    \n    console.log(`‚úÖ Configuration updated: ${oldConfig.deviceTier} -> ${newConfig.deviceTier}`);\n    this.logEngineStatus();\n  }\n  \n  /**\n   * Handle configuration changes\n   */\n  private handleConfigChange(newConfig: AdaptiveAudioConfig, reason: string): void {\n    console.log(`üì° Received configuration change: ${reason}`);\n    this.applyNewConfiguration(newConfig, reason);\n  }\n  \n  /**\n   * Reduce current polyphony\n   */\n  private reducePolyphony(targetPolyphony: number): void {\n    let stoppedCount = 0;\n    \n    while (this.currentPolyphony > targetPolyphony && stoppedCount < 10) {\n      if (this.stopOldestSource()) {\n        stoppedCount++;\n      } else {\n        break;\n      }\n    }\n    \n    console.log(`üîá Reduced polyphony by ${stoppedCount} sources`);\n  }\n  \n  /**\n   * Stop oldest source to make room\n   */\n  private stopOldestSource(preferredTrackId?: string): boolean {\n    // Try to stop from the preferred track first\n    if (preferredTrackId && this.activeSources.has(preferredTrackId)) {\n      const sources = this.activeSources.get(preferredTrackId)!;\n      if (sources.length > 0) {\n        const oldest = sources.shift();\n        if (oldest) {\n          try {\n            oldest.stop();\n            this.currentPolyphony = Math.max(0, this.currentPolyphony - 1);\n            return true;\n          } catch (e) {\n            // Already ended\n          }\n        }\n      }\n    }\n    \n    // Otherwise find any track with active sources\n    for (const [trackId, sources] of this.activeSources) {\n      if (sources.length > 0) {\n        const oldest = sources.shift();\n        if (oldest) {\n          try {\n            oldest.stop();\n            this.currentPolyphony = Math.max(0, this.currentPolyphony - 1);\n            console.log(`üõë Stopped oldest source from: ${trackId}`);\n            return true;\n          } catch (e) {\n            // Already ended\n          }\n        }\n      }\n    }\n    \n    return false;\n  }\n  \n  /**\n   * Start playback with adaptive scheduling\n   */\n  async start(): Promise<void> {\n    if (this.isPlaying) return;\n    \n    console.log('‚ñ∂Ô∏è Starting adaptive audio engine...');\n    \n    // Resume AudioContext\n    if (this.audioContext.state === 'suspended') {\n      console.log('üîß Resuming suspended AudioContext...');\n      await this.audioContext.resume();\n    }\n    \n    this.isPlaying = true;\n    this.currentStep = 0;\n    this.nextStepTime = this.audioContext.currentTime + 0.005;\n    \n    // Use adaptive scheduling interval\n    const lookaheadTime = Math.max(25, this.config.scheduleAheadTime * 1000); // Convert to ms, minimum 25ms\n    this.schedulerInterval = setInterval(this.adaptiveScheduler.bind(this), lookaheadTime);\n    \n    console.log(`‚úÖ Adaptive audio engine started (lookahead: ${lookaheadTime}ms)`);\n  }\n  \n  /**\n   * Adaptive scheduler with performance monitoring\n   */\n  private adaptiveScheduler(): void {\n    if (!this.isPlaying) return;\n    \n    const startTime = performance.now();\n    \n    const stepDuration = (60 / this.bpm) / 4;\n    const currentTime = this.audioContext.currentTime;\n    const scheduleAhead = this.config.scheduleAheadTime;\n    \n    while (this.nextStepTime < currentTime + scheduleAhead) {\n      this.scheduleStep(this.currentStep, this.nextStepTime);\n      this.nextStepTime += stepDuration;\n      this.currentStep = (this.currentStep + 1) % 16;\n    }\n    \n    // Monitor scheduler performance\n    const schedulerTime = performance.now() - startTime;\n    this.performanceMonitor.recordSchedulerTime(schedulerTime);\n    \n    if (schedulerTime > 10) { // > 10ms is concerning\n      console.warn(`‚ö†Ô∏è Scheduler took ${schedulerTime.toFixed(2)}ms - may need optimization`);\n    }\n  }\n  \n  /**\n   * Schedule step with adaptive loading\n   */\n  private scheduleStep(stepIndex: number, baseTime: number): void {\n    const activeTracks = this.getActiveTracksForStep(stepIndex);\n    \n    activeTracks.forEach(async (trackId) => {\n      const track = this.tracks.get(trackId);\n      if (!track) return;\n      \n      // Calculate groove offset\n      const grooveOffset = this.calculateGrooveOffset(track, stepIndex);\n      const adjustedTime = baseTime + grooveOffset;\n      \n      // Play track sample with adaptive loading\n      await this.playTrackSample(trackId, track.volume, adjustedTime);\n    });\n  }\n  \n  /**\n   * Calculate groove timing offset\n   */\n  private calculateGrooveOffset(track: TrackPattern, stepIndex: number): number {\n    if (!track.groove || !track.groove[stepIndex]) {\n      return 0;\n    }\n    \n    const grooveDot = track.groove[stepIndex];\n    if (grooveDot.offsetPercent === 0) {\n      return 0;\n    }\n    \n    const stepDuration = (60 / this.bpm) / 4;\n    const offsetRatio = grooveDot.offsetPercent / 100;\n    const maxOffset = stepDuration * 0.75;\n    const calculatedOffset = offsetRatio * maxOffset;\n    \n    return Math.max(-0.15, Math.min(0.15, calculatedOffset));\n  }\n  \n  /**\n   * Get active tracks for step\n   */\n  private getActiveTracksForStep(stepIndex: number): string[] {\n    const activeTracks: string[] = [];\n    \n    this.tracks.forEach((track, trackId) => {\n      if (track.steps[stepIndex] && !track.muted) {\n        activeTracks.push(trackId);\n      }\n    });\n    \n    return activeTracks;\n  }\n  \n  /**\n   * Stop playback\n   */\n  stop(): void {\n    if (!this.isPlaying) return;\n    \n    console.log('‚èπÔ∏è Stopping adaptive audio engine...');\n    \n    this.isPlaying = false;\n    \n    if (this.schedulerInterval) {\n      clearInterval(this.schedulerInterval);\n      this.schedulerInterval = null;\n    }\n    \n    this.stopAllActiveSources();\n    this.nextStepTime = 0;\n    this.currentStep = 0;\n    \n    console.log('‚úÖ Adaptive audio engine stopped');\n  }\n  \n  /**\n   * Stop all active sources\n   */\n  private stopAllActiveSources(): void {\n    let stoppedCount = 0;\n    \n    for (const [_, sources] of this.activeSources) {\n      sources.forEach(source => {\n        try {\n          source.stop();\n          stoppedCount++;\n        } catch (e) {\n          // Already ended\n        }\n      });\n      sources.length = 0;\n    }\n    \n    this.currentPolyphony = 0;\n    \n    if (stoppedCount > 0) {\n      console.log(`üõë Stopped ${stoppedCount} active sources`);\n    }\n  }\n  \n  /**\n   * Update track configuration\n   */\n  updatePattern(trackId: string, stepIndex: number, active: boolean): void {\n    const track = this.tracks.get(trackId);\n    if (track && stepIndex >= 0 && stepIndex < 16) {\n      track.steps[stepIndex] = active;\n    }\n  }\n  \n  updateVolume(trackId: string, volume: number): void {\n    const track = this.tracks.get(trackId);\n    if (track) {\n      track.volume = Math.max(0, Math.min(1, volume));\n    }\n  }\n  \n  updateSelectedSample(trackId: string, sampleId: string): void {\n    const track = this.tracks.get(trackId);\n    if (track) {\n      track.selectedSampleId = sampleId;\n      // Preload new sample if strategy allows\n      if (this.config.preloadStrategy !== 'minimal') {\n        this.sampleLoader.loadSample(sampleId);\n      }\n    }\n  }\n  \n  /**\n   * Get engine status for debugging\n   */\n  getEngineStatus(): {\n    config: AdaptiveAudioConfig;\n    performance: AudioPerformanceStats;\n    cache: any;\n    polyphony: { current: number; max: number };\n    memoryPressure: string;\n  } {\n    return {\n      config: this.config,\n      performance: this.performanceMonitor.getStats(),\n      cache: this.sampleLoader.getCacheStats(),\n      polyphony: { current: this.currentPolyphony, max: this.maxPolyphony },\n      memoryPressure: this.memoryPressureLevel\n    };\n  }\n  \n  /**\n   * Log engine status\n   */\n  private logEngineStatus(): void {\n    console.log('üéµ Adaptive Audio Engine Status:');\n    console.table({\n      'Device Tier': this.config.deviceTier,\n      'Audio Quality': this.config.audioQuality,\n      'Max Polyphony': this.maxPolyphony,\n      'Current Polyphony': this.currentPolyphony,\n      'Sample Rate': `${this.audioContext.sampleRate}Hz`,\n      'Preload Strategy': this.config.preloadStrategy,\n      '64kbps Priority': this.config.use64kbpsPriority ? 'Yes' : 'No'\n    });\n  }\n  \n  // Legacy compatibility methods\n  setBpm(newBpm: number): void { this.bpm = Math.max(60, Math.min(200, newBpm)); }\n  setBPM(newBpm: number): void { this.setBpm(newBpm); }\n  getCurrentStep(): number { return this.currentStep; }\n  isEnginePlaying(): boolean { return this.isPlaying; }\n  getBpm(): number { return this.bpm; }\n  getTrack(trackId: string): TrackPattern | undefined { return this.tracks.get(trackId); }\n  updateGroove(trackId: string, groove: GrooveDot[]): void {\n    const track = this.tracks.get(trackId);\n    if (track) {\n      track.groove = [...groove];\n    }\n  }\n  \n  dispose(): void {\n    this.stop();\n    this.performanceMonitor.stop();\n    this.sampleLoader.clearCache();\n    this.tracks.clear();\n    \n    if (this.audioContext.state !== 'closed') {\n      this.audioContext.close();\n    }\n    \n    console.log('üßπ Adaptive audio engine disposed');\n  }\n}\n\n/**\n * Performance Monitor for audio engine\n */\nclass PerformanceMonitor {\n  private stats: AudioPerformanceStats = {\n    cpuUsage: 0,\n    memoryUsage: 0,\n    audioLatency: 0,\n    droppedFrames: 0,\n    currentPolyphony: 0,\n    cacheHitRate: 0\n  };\n  \n  private monitorInterval: number | null = null;\n  private callback?: (stats: AudioPerformanceStats) => void;\n  private schedulerTimes: number[] = [];\n  \n  start(callback: (stats: AudioPerformanceStats) => void): void {\n    this.callback = callback;\n    \n    this.monitorInterval = setInterval(() => {\n      this.updateStats();\n      if (this.callback) {\n        this.callback(this.stats);\n      }\n    }, 5000); // Update every 5 seconds\n  }\n  \n  stop(): void {\n    if (this.monitorInterval) {\n      clearInterval(this.monitorInterval);\n      this.monitorInterval = null;\n    }\n  }\n  \n  recordSamplePlayback(sampleId: string, polyphony: number): void {\n    this.stats.currentPolyphony = polyphony;\n  }\n  \n  recordSchedulerTime(timeMs: number): void {\n    this.schedulerTimes.push(timeMs);\n    if (this.schedulerTimes.length > 50) {\n      this.schedulerTimes.shift();\n    }\n  }\n  \n  private updateStats(): void {\n    // Update CPU usage estimate\n    if (this.schedulerTimes.length > 0) {\n      const avgSchedulerTime = this.schedulerTimes.reduce((a, b) => a + b, 0) / this.schedulerTimes.length;\n      this.stats.cpuUsage = Math.min(100, avgSchedulerTime * 4); // Rough estimate\n    }\n    \n    // Update memory usage\n    try {\n      // @ts-ignore - performance.memory is experimental\n      const memory = performance.memory;\n      if (memory) {\n        this.stats.memoryUsage = memory.usedJSHeapSize / memory.totalJSHeapSize;\n      }\n    } catch (e) {\n      // Memory API not available\n    }\n    \n    // Audio latency estimation (simplified)\n    this.stats.audioLatency = 50; // Placeholder\n  }\n  \n  getStats(): AudioPerformanceStats {\n    return { ...this.stats };\n  }\n}